# ü¶ô TinyLLaMA MMLU Benchmark & Distillation

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:

1. –ó–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ [TinyLLaMA-1.1B-Chat](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat)
2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏
3. –ü—Ä–æ–≥–æ–Ω –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ [MMLU](https://huggingface.co/datasets/cais/mmlu)
4. –ü—Ä–æ—Å—Ç—É—é –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—é ‚Äî —É–¥–∞–ª–µ–Ω–∏–µ —á–∞—Å—Ç–∏ –¥–µ–∫–æ–¥–µ—Ä–æ–≤
5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –¥–æ –∏ –ø–æ—Å–ª–µ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
conda create -n tinyllama-env python=3.10 pip -y
pip install -r requirements.txt 
pip install numpy==1.24.3
pip install triton
pip install --upgrade bitsandbytes