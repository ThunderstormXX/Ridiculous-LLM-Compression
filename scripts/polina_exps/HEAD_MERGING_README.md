# Объединение Attention-голов в Llama3.1-8B

Этот эксперимент исследует объединение похожих attention-голов в модели Llama3.1-8B на основе косинусной схожести их весов.

## Описание эксперимента

**Цель**: Найти похожие attention-головы внутри каждого слоя, усреднить их веса, и сравнить качество модели до и после объединения.

**Метод**: 
- Вычисление косинусной схожести между весами Q-проекций голов
- Объединение голов с схожестью выше заданного порога путем усреднения весов Q, K, V, O
- Сохранение архитектуры модели (32 головы остаются, но некоторые становятся идентичными)

**Метрики**: Perplexity и Accuracy на WikiText-2

## Структура файлов

```
scripts/
├── merge_attention_heads.py      # Основной скрипт эксперимента
├── analyze_head_merging.py       # Анализ результатов
└── bash/
    └── run_head_merging.sh       # Bash-скрипт для запуска экспериментов
```

## Использование

### 1. Быстрый запуск

```bash
# Запуск с параметрами по умолчанию (пороги: 0.98, 0.99, 0.995)
./scripts/bash/run_head_merging.sh
```

### 2. Настройка параметров

```bash
# Запуск с кастомными параметрами
./scripts/bash/run_head_merging.sh \
    --model_path src/checkpoints/llama3.1-8b \
    --output_dir results/head_merging \
    --device cuda \
    --thresholds 0.98,0.99,0.995
```

### 3. Запуск отдельного эксперимента

```bash
# Один эксперимент с конкретным порогом
python scripts/merge_attention_heads.py \
    --model_path src/checkpoints/llama3.1-8b \
    --threshold 0.99 \
    --output_dir results/head_merging \
    --device cuda
```

### 4. Анализ результатов

```bash
# Анализ всех результатов в директории
python scripts/analyze_head_merging.py \
    --results_dir results/head_merging \
    --output_dir results/head_merging/analysis
```

## Параметры

### merge_attention_heads.py

- `--model_path`: Путь к чекпоинту модели (по умолчанию: `src/checkpoints/llama3.1-8b`)
- `--threshold`: Порог косинусной схожести для объединения (по умолчанию: 0.99)
- `--layers`: Конкретные слои для анализа (по умолчанию: все слои)
- `--output_dir`: Директория для сохранения результатов (по умолчанию: `results/head_merging`)
- `--device`: Устройство для вычислений (по умолчанию: `cuda`)

### run_head_merging.sh

- `--model_path`: Путь к модели
- `--output_dir`: Директория результатов
- `--device`: Устройство
- `--thresholds`: Список порогов через запятую (например: `0.98,0.99,0.995`)

## Выходные файлы

### Результаты эксперимента

```
results/head_merging/
├── results_threshold_0.98.json   # Результаты для порога 0.98
├── results_threshold_0.99.json   # Результаты для порога 0.99
├── results_threshold_0.995.json  # Результаты для порога 0.995
├── comparison_threshold_0.99.png # График сравнения метрик
├── merged_pairs_threshold_0.99.png # График количества объединенных пар
└── analysis/                     # Директория с анализом
    ├── threshold_comparison.png  # Сравнение всех порогов
    └── similarity_matrices_*.png # Матрицы схожести по слоям
```

### Формат JSON результатов

```json
{
  "threshold": 0.99,
  "original_metrics": {
    "perplexity": 15.234,
    "accuracy": 0.456
  },
  "merged_metrics": {
    "perplexity": 15.678,
    "accuracy": 0.445
  },
  "total_merged_pairs": 12,
  "layer_results": {
    "0": {
      "num_pairs": 2,
      "pairs": [[1, 5, 0.992], [3, 7, 0.991]],
      "similarity_matrix": [[...]]
    }
  }
}
```

## Интерпретация результатов

### Метрики качества

- **Perplexity**: Чем ниже, тем лучше. Увеличение указывает на ухудшение языкового моделирования
- **Accuracy**: Чем выше, тем лучше. Точность предсказания следующего токена

### Анализ порогов

- **Высокий порог (0.995)**: Мало объединений, минимальное влияние на качество
- **Средний порог (0.99)**: Умеренное количество объединений, баланс между сжатием и качеством  
- **Низкий порог (0.98)**: Много объединений, возможное значительное ухудшение качества

### Графики

1. **threshold_comparison.png**: Показывает как метрики изменяются с порогом
2. **comparison_threshold_X.png**: Сравнение до/после для конкретного порога
3. **merged_pairs_threshold_X.png**: Количество объединенных пар по слоям
4. **similarity_matrices_*.png**: Визуализация схожести голов в разных слоях

## Ожидаемые результаты

- **Слои с высокой схожестью**: Обычно средние слои модели имеют больше похожих голов
- **Влияние на качество**: Небольшое ухудшение perplexity при разумных порогах (0.99+)
- **Эффективность сжатия**: Возможность идентификации избыточных голов для последующего удаления

## Требования

- Python 3.8+
- PyTorch 2.0+
- Transformers 4.30+
- scikit-learn
- matplotlib
- numpy
- tqdm

## Примечания

- Эксперимент не изменяет архитектуру модели - количество голов остается 32
- Объединенные головы становятся идентичными, что может служить основой для последующего сжатия
- Время выполнения зависит от размера модели и количества анализируемых слоев
- Рекомендуется использовать GPU для ускорения вычислений