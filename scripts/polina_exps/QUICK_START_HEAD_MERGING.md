# Быстрый старт: Объединение Attention-голов

## Подготовка

1. Убедитесь, что модель находится в `src/checkpoints/llama3.1-8b/`
2. Установите зависимости: `pip install -r requirements.txt`

## Запуск эксперимента

### Вариант 1: Автоматический запуск с несколькими порогами

```bash
# Запуск с параметрами по умолчанию (пороги: 0.98, 0.99, 0.995)
./scripts/bash/run_head_merging.sh
```

### Вариант 2: Ручной запуск одного эксперимента

```bash
# Эксперимент с порогом 0.99
python scripts/merge_attention_heads.py \
    --model_path src/checkpoints/llama3.1-8b \
    --threshold 0.99 \
    --output_dir results/head_merging \
    --device cuda
```

### Вариант 3: Тестирование функциональности

```bash
# Быстрый тест системы
python scripts/test_head_merging.py
```

## Результаты

Результаты сохраняются в `results/head_merging/`:
- `results_threshold_X.json` - детальные результаты
- `comparison_threshold_X.png` - графики сравнения
- `analysis/` - сводный анализ всех экспериментов

## Интерпретация

- **Perplexity**: ↓ лучше (меньше = лучше языковое моделирование)
- **Accuracy**: ↑ лучше (больше = лучше предсказание токенов)
- **Merged Pairs**: количество объединенных пар голов

## Ожидаемое время выполнения

- Один эксперимент: ~10-15 минут
- Полный набор (3 порога): ~30-45 минут
- Тест функциональности: ~2-3 минуты

## Устранение проблем

1. **Ошибка CUDA**: Используйте `--device cpu` для тестирования
2. **Нет модели**: Проверьте путь в `--model_path`
3. **Мало памяти**: Уменьшите размер датасета в коде

## Следующие шаги

После получения результатов:
1. Изучите файлы в `results/head_merging/analysis/`
2. Выберите оптимальный порог на основе графиков
3. Используйте результаты для дальнейшего сжатия модели