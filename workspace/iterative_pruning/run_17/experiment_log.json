[
  {
    "step": 0,
    "action": "baseline",
    "method": "iterative",
    "layers_total": 32,
    "perplexity": 1.7042714510062649,
    "timestamp": "2025-08-09T15:56:33.611083"
  },
  {
    "action": "prune",
    "step": 1,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 1.712236304009597,
    "layers_remaining": 31,
    "timestamp": "2025-08-09T16:26:17.135165"
  },
  {
    "action": "train",
    "step": 1,
    "lora_layer": 18,
    "perplexity": 1.7849120114037227,
    "training_steps": 1666,
    "total_steps_used": 1666,
    "budget_remaining": 3334,
    "timestamp": "2025-08-09T16:26:17.135649"
  }
]