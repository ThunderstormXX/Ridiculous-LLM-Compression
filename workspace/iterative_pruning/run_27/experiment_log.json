[
  {
    "step": 0,
    "action": "baseline",
    "method": "iterative",
    "layers_total": 32,
    "perplexity": 0.20791671244967447,
    "timestamp": "2025-08-09T17:35:49.595802"
  },
  {
    "action": "prune",
    "step": 1,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 0.21783510004157017,
    "layers_remaining": 31,
    "timestamp": "2025-08-09T17:38:00.434034"
  },
  {
    "action": "train",
    "step": 1,
    "lora_layer": 18,
    "perplexity": 0.21788255652059133,
    "training_steps": 3,
    "total_steps_used": 3,
    "budget_remaining": 7,
    "timestamp": "2025-08-09T17:38:00.434776"
  },
  {
    "action": "prune",
    "step": 2,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 0.22752124207120442,
    "layers_remaining": 30,
    "timestamp": "2025-08-09T17:40:41.420467"
  },
  {
    "action": "train",
    "step": 2,
    "lora_layer": 18,
    "perplexity": 0.22752227311284764,
    "training_steps": 3,
    "total_steps_used": 6,
    "budget_remaining": 4,
    "timestamp": "2025-08-09T17:40:41.420984"
  },
  {
    "action": "prune",
    "step": 3,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 0.23736069462569168,
    "layers_remaining": 29,
    "timestamp": "2025-08-09T17:43:18.498325"
  },
  {
    "action": "train",
    "step": 3,
    "lora_layer": 18,
    "perplexity": 0.23735981907573467,
    "training_steps": 3,
    "total_steps_used": 9,
    "budget_remaining": 1,
    "timestamp": "2025-08-09T17:43:18.499359"
  }
]