[
  {
    "step": 0,
    "action": "baseline",
    "method": "iterative",
    "layers_total": 32,
    "perplexity": 528.2581787109375,
    "timestamp": "2025-08-07T16:25:20.834947"
  },
  {
    "action": "prune",
    "step": 1,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 558.0319213867188,
    "layers_remaining": 31,
    "timestamp": "2025-08-07T16:25:36.504549"
  },
  {
    "action": "train",
    "step": 1,
    "lora_layer": 18,
    "perplexity": 558.4617919921875,
    "training_steps": 3,
    "total_steps_used": 3,
    "budget_remaining": 7,
    "timestamp": "2025-08-07T16:25:36.506097"
  },
  {
    "action": "prune",
    "step": 2,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 601.1661987304688,
    "layers_remaining": 30,
    "timestamp": "2025-08-07T16:25:53.626230"
  },
  {
    "action": "train",
    "step": 2,
    "lora_layer": 18,
    "perplexity": 601.184814453125,
    "training_steps": 3,
    "total_steps_used": 6,
    "budget_remaining": 4,
    "timestamp": "2025-08-07T16:25:53.629002"
  },
  {
    "action": "prune",
    "step": 3,
    "removed_layer": 19,
    "lora_layer": 18,
    "perplexity": 645.3128051757812,
    "layers_remaining": 29,
    "timestamp": "2025-08-07T16:26:10.088147"
  },
  {
    "action": "train",
    "step": 3,
    "lora_layer": 18,
    "perplexity": 645.3607788085938,
    "training_steps": 3,
    "total_steps_used": 9,
    "budget_remaining": 1,
    "timestamp": "2025-08-07T16:26:10.089613"
  }
]